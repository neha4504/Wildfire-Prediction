{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ab97bf6-0223-4a01-98e5-399afd65c530",
   "metadata": {},
   "source": [
    "<h1>Introduction</h1>\n",
    "\n",
    "This notebook implements a wildfire prediction pipeline using the Wildfire Prediction Dataset from Kaggle. The dataset contains satellite images (350x350px) organized into train, test, and valid folders, each with wildfire and nowildfire subfolders. The goal is to classify images as wildfire or non-wildfire using two models: a custom Convolutional Neural Network (CNN) and a pretrained ResNet50 model with transfer learning. The following steps:\n",
    "\n",
    "<b>Data Cleaning:</b> Check for corrupt images or inconsistencies and visualize the dataset.\n",
    "\n",
    "<b>Data Preprocessing:</b> Prepare images for modeling using TensorFlowâ€™s ImageDataGenerator.\n",
    "\n",
    "<b>Modeling:</b> Implement a custom CNN and a pretrained ResNet50 model.\n",
    "\n",
    "<b>Results and Comparison:</b> Evaluate and compare model performance using accuracy, precision, recall, F1-score, confusion matrices, and ROC curves.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10e5e9ac-2ec1-4cbf-9030-26ec8a39f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb9b2339-d5e0-403f-ba42-aa0952792d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'C:\\\\Users\\\\DELL\\\\Downloads\\\\wildfire-prediction-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ce95c4d-b227-427f-8b5d-5191e4f45009",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(base_dir, 'train')\n",
    "valid_dir = os.path.join(base_dir, 'valid')\n",
    "test_dir = os.path.join(base_dir, 'test') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b224f2-3884-433e-9a42-f8321221e0ab",
   "metadata": {},
   "source": [
    "<h1>Step 1: Data Cleaning</h1>\n",
    "\n",
    "<b>Objective:</b> Ensure the dataset is clean by checking for corrupt images, verifying folder structure, and visualizing class distribution.\n",
    "\n",
    "<b>Rationale:</b> Image datasets can have corrupt files or imbalanced classes, which can affect model training. Check for issues and visualize the number of images per class to understand the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da3f6478-9108-4ae4-a4ea-c7ef6c5c88fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for corrupt images\n",
    "import glob\n",
    "from PIL import Image\n",
    "def verify_image(file):\n",
    "    try:\n",
    "        img = Image.open(file)\n",
    "        img.verify()\n",
    "        img.close()\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "320f7e77-10f1-4bb3-b6fa-1ce4e5bbb141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check images with multiprocessing\n",
    "# Function to check images in a directory\n",
    "def check_images(directory, max_images=1000):\n",
    "    print(f\"Processing {directory}...\")\n",
    "    corrupt_files = []\n",
    "    \n",
    "    # Collect image paths (limit to max_images)\n",
    "    image_paths = []\n",
    "    for subdir in ['wildfire', 'nowildfire']:\n",
    "        path = os.path.join(directory, subdir, '*.jpg')  # Assuming JPG\n",
    "        subdir_paths = glob.glob(path)\n",
    "        np.random.shuffle(subdir_paths)  # Random sample\n",
    "        image_paths.extend(subdir_paths[:max_images//2])  # 500 per class\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(f\"No images found in {directory}. Check path or file extensions.\")\n",
    "        return corrupt_files\n",
    "    \n",
    "    # Verify images with multiprocessing\n",
    "    start_time = time.time()\n",
    "    with Pool(processes=os.cpu_count()) as pool:\n",
    "        results = list(tqdm(pool.imap(verify_image, image_paths), \n",
    "                           total=len(image_paths), \n",
    "                           desc=f\"Checking {os.path.basename(directory)}\"))\n",
    "    \n",
    "    corrupt_files = [r for r in results if r is not None]\n",
    "    \n",
    "    if corrupt_files:\n",
    "        print(f\"Found {len(corrupt_files)} corrupt files in {directory}:\")\n",
    "        for file in corrupt_files:\n",
    "            print(f\"Corrupt: {file}\")\n",
    "    else:\n",
    "        print(f\"No corrupt files found in {directory} sample.\")\n",
    "    \n",
    "    print(f\"Finished {directory} in {time.time() - start_time:.2f} seconds.\")\n",
    "    return corrupt_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ebe72c-e876-4420-af5c-31185fc829ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting corrupt image check...\n",
      "Processing C:\\Users\\DELL\\Downloads\\wildfire-prediction-dataset\\train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking train:   0%|                                                                         | 0/1000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Check for corrupt images in train, valid, and test sets\n",
    "\n",
    "from multiprocessing import Pool,cpu_count\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "print(\"Starting corrupt image check...\")\n",
    "train_corrupt = check_images(train_dir)\n",
    "valid_corrupt = check_images(valid_dir)\n",
    "test_corrupt = check_images(test_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16a1a87e-3719-46ec-8e2b-b17453dfd078",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_corrupt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Report corrupt files\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m total_corrupt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_corrupt\u001b[49m \u001b[38;5;241m+\u001b[39m valid_corrupt \u001b[38;5;241m+\u001b[39m test_corrupt)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_corrupt \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTotal: Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_corrupt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m corrupt files. Consider removing them.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_corrupt' is not defined"
     ]
    }
   ],
   "source": [
    "# Report corrupt files\n",
    "total_corrupt = len(train_corrupt + valid_corrupt + test_corrupt)\n",
    "if total_corrupt > 0:\n",
    "    print(f\"\\nTotal: Found {total_corrupt} corrupt files. Consider removing them.\")\n",
    "else:\n",
    "    print(\"\\nTotal: No corrupt files found. Dataset is clean!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc76cf-65d0-48eb-a23d-abc4a6f2c168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5997c8ea-0a85-44ed-ac51-37379f88022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images per class\n",
    "def count_images(directory):\n",
    "    wildfire_count = len(glob.glob(os.path.join(directory, 'wildfire', '*.jpg')))\n",
    "    nowildfire_count = len(glob.glob(os.path.join(directory, 'nowildfire', '*.jpg')))\n",
    "    return wildfire_count, nowildfire_count\n",
    "\n",
    "train_wf, train_nwf = count_images(train_dir)\n",
    "valid_wf, valid_nwf = count_images(valid_dir)\n",
    "test_wf, test_nwf = count_images(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8693793-0604-4540-a402-f0ff3dc7db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "labels = ['Wildfire', 'No Wildfire']\n",
    "train_counts = [train_wf, train_nwf]\n",
    "valid_counts = [valid_wf, valid_nwf]\n",
    "test_counts = [test_wf, test_nwf]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "x = np.arange(len(labels))\n",
    "width = 0.25\n",
    "\n",
    "plt.bar(x - width, train_counts, width, label='Train')\n",
    "plt.bar(x, valid_counts, width, label='Validation')\n",
    "plt.bar(x + width, test_counts, width, label='Test')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Class Distribution Across Dataset Splits')\n",
    "plt.xticks(x, labels)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848560c7-0f9e-4840-bf0a-13e2f9956c79",
   "metadata": {},
   "source": [
    "<h2>Insights:</h2>\n",
    "\n",
    "If corrupt files are found, they should be removed manually or programmatically to avoid errors during training.\n",
    "\n",
    "If the class distribution is imbalanced, weâ€™ll address it in preprocessing (e.g., using class weights or data augmentation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b238c46-092c-4b00-8ce0-8ea48a6a65fb",
   "metadata": {},
   "source": [
    "<h1>Step 2: Data Preprocessing</h1>\n",
    "<b>Objective:</b> Load and preprocess images for modeling, including resizing, normalization, and data augmentation. Use the provided train, valid, and test splits.\n",
    "\n",
    "<b>Rationale:</b> Images need to be resized to a consistent size (e.g., 224x224 for ResNet50 compatibility), normalized to [0,1], and augmented to improve model generalization. The dataset is already split, so weâ€™ll use the provided folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b22d9-3568-4e32-b573-bfbf6f08cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image parameters\n",
    "IMG_SIZE = (224, 224)  # Standard size for ResNet50 and custom CNN\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc42561-2538-4be1-b1b8-9e19828f77d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators with augmentation for training\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c743a67-4e7d-4b55-a317-9390955baa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation and test sets: only rescale, no augmentation\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d0bc17-98a2-48db-bb79-71030f56e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from directories\n",
    "# Train set\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "# Validation set\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "# Test set\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d755a-3d48-458e-b3f9-004280deafbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify class indices\n",
    "print(\"Class indices:\", train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c78457a-361b-4a7b-a896-0d648486b63b",
   "metadata": {},
   "source": [
    "<h2>Insights:</h2>\n",
    "\n",
    "<b>Data Augmentation:</b> Applied to the training set to increase robustness (e.g., rotations, flips). Not applied to validation/test sets to ensure unbiased evaluation.\n",
    "\n",
    "<b>Normalization:</b> Rescaling to [0,1] ensures consistent input ranges for the neural networks.\n",
    "\n",
    "<b>Class Indices:</b> Confirm that wildfire is class 1 and nowildfire is class 0 for binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6bb68e-2527-477c-a149-2c2781acee27",
   "metadata": {},
   "source": [
    "<h1>Step 3: Modeling\n",
    "Weâ€™ll implement two models:</h1>\n",
    "\n",
    "<b>Custom CNN:</b> A simple convolutional neural network designed for this task.\n",
    "\n",
    "<b>PretrainedResNet50:</b> A transfer learning model using ResNet50 with weights pretrained on ImageNet.\n",
    "\n",
    "<h3>Custom CNN</h3>\n",
    "<b>Rationale:</b> A custom CNN allows us to design a lightweight model tailored to the dataset. Weâ€™ll use a few convolutional layers followed by dense layers for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631fe283-e958-41cb-8fbc-a7e41b23ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34c77ca-e05f-4a4d-983d-d4e596eaf914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build custom CNN\n",
    "custom_cnn = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ef1a40-a31f-401f-ba96-eee75970f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "custom_cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468906bb-25b0-4ddd-a7e1-4b95df858e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "custom_cnn_history = custom_cnn.fit(\n",
    "    train_generator,\n",
    "    epochs=1,\n",
    "    validation_data=valid_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1124849-88a9-4fab-9e47-ab0f4669139e",
   "metadata": {},
   "source": [
    "<h3>Pretrained ResNet50</h3>\n",
    "<b>Rationale:</b> ResNet50, pretrained on ImageNet, leverages learned features for better performance on image classification tasks, especially with limited data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed66de2-5962-430c-afe8-661fcfc08c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31acea9a-6254-4a4a-9f29-81fc098086d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 with ImageNet weights, exclude top layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cedae6-638c-4918-a4e7-b259c6cb82ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze base model layers\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602967f1-a0ef-4ef4-b4c1-bb76251260df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build transfer learning model\n",
    "resnet_model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c776962-b732-4863-b8a6-1072f9d083f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "resnet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1befcf-5b03-4f9e-a5fc-2909ffdd47e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "resnet_history = resnet_model.fit(\n",
    "    train_generator,\n",
    "    epochs=1,\n",
    "    validation_data=valid_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2ae84b-0341-425f-86f5-ba5d3af39809",
   "metadata": {},
   "source": [
    "<h2>Insights:</h2>\n",
    "\n",
    "<b>Custom CNN:</b> Simple architecture, but may struggle with complex patterns due to limited depth.\n",
    "\n",
    "<b>ResNet50: </b>Likely to perform better due to pretrained features, but may overfit if not enough data augmentation is used.\n",
    "\n",
    "<b>Challenges:</b> If the dataset is small, ResNet50 may not generalize well without fine-tuning. We kept the base model frozen for simplicity but could unfreeze layers for better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb794372-13bc-463d-a7ba-b4f3737ab88d",
   "metadata": {},
   "source": [
    "<h1>Step 4: Results and Comparison</h1>\n",
    "\n",
    "<b>Objective:</b> Evaluate both models on the test set using accuracy, precision, recall, and F1-score. Visualize performance with confusion matrices, ROC curves, and loss curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1c4f48-8c64-40e6-ab69-d9d9242899f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models on test set\n",
    "custom_cnn_results = custom_cnn.evaluate(test_generator)\n",
    "resnet_results = resnet_model.evaluate(test_generator)\n",
    "\n",
    "print(f\"Custom CNN - Test Loss: {custom_cnn_results[0]:.4f}, Test Accuracy: {custom_cnn_results[1]:.4f}\")\n",
    "print(f\"ResNet50 - Test Loss: {resnet_results[0]:.4f}, Test Accuracy: {resnet_results[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f890381e-230a-4bc1-8e78-ee024c16c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for confusion matrix and classification report\n",
    "custom_cnn_pred = (custom_cnn.predict(test_generator) > 0.5).astype(\"int32\")\n",
    "resnet_pred = (resnet_model.predict(test_generator) > 0.5).astype(\"int32\")\n",
    "true_labels = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f25438-900e-4444-9149-60a406564120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"\\nCustom CNN Classification Report:\")\n",
    "print(classification_report(true_labels, custom_cnn_pred, target_names=['No Wildfire', 'Wildfire']))\n",
    "\n",
    "print(\"\\nResNet50 Classification Report:\")\n",
    "print(classification_report(true_labels, resnet_pred, target_names=['No Wildfire', 'Wildfire']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c62f122-0261-4a4b-b652-3760ac2c5917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "sns.heatmap(confusion_matrix(true_labels, custom_cnn_pred), annot=True, fmt='d', cmap='Blues', ax=ax1)\n",
    "ax1.set_title('Custom CNN Confusion Matrix')\n",
    "ax1.set_xlabel('Predicted')\n",
    "ax1.set_ylabel('True')\n",
    "\n",
    "sns.heatmap(confusion_matrix(true_labels, resnet_pred), annot=True, fmt='d', cmap='Blues', ax=ax2)\n",
    "ax2.set_title('ResNet50 Confusion Matrix')\n",
    "ax2.set_xlabel('Predicted')\n",
    "ax2.set_ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae340d4-55a9-4ad2-bc03-b2c92bd7b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "custom_cnn_prob = custom_cnn.predict(test_generator)\n",
    "resnet_prob = resnet_model.predict(test_generator)\n",
    "\n",
    "custom_fpr, custom_tpr, _ = roc_curve(true_labels, custom_cnn_prob)\n",
    "resnet_fpr, resnet_tpr, _ = roc_curve(true_labels, resnet_prob)\n",
    "custom_auc = auc(custom_fpr, custom_tpr)\n",
    "resnet_auc = auc(resnet_fpr, resnet_tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(custom_fpr, custom_tpr, label=f'Custom CNN (AUC = {custom_auc:.2f})')\n",
    "plt.plot(resnet_fpr, resnet_tpr, label=f'ResNet50 (AUC = {resnet_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b01c06f-1e37-4c2c-9a1c-36d1d6604403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(custom_cnn_history.history['loss'], label='Custom CNN Train Loss')\n",
    "plt.plot(custom_cnn_history.history['val_loss'], label='Custom CNN Val Loss')\n",
    "plt.plot(resnet_history.history['loss'], label='ResNet50 Train Loss')\n",
    "plt.plot(resnet_history.history['val_loss'], label='ResNet50 Val Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(custom_cnn_history.history['accuracy'], label='Custom CNN Train Acc')\n",
    "plt.plot(custom_cnn_history.history['val_accuracy'], label='Custom CNN Val Acc')\n",
    "plt.plot(resnet_history.history['accuracy'], label='ResNet50 Train Acc')\n",
    "plt.plot(resnet_history.history['val_accuracy'], label='ResNet50 Val Acc')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf214_env)",
   "language": "python",
   "name": "tf214_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
